Starting code feedback for Zhongbin, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 8.05 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: HPC, .git, week1, Groupwork, week2, miniproject, Feedback, week3

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
*~
*.tmp
week1/sandbox



**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
MY CMEE Coursework Repository
CMEECoursework repository contains the in-class work and coursework in each weeks. 
There are three directories whcih are week 1 to 3, each contains code, data, results and sandbox.
Code directory is for saving all the code and scripts.
Data directory is for saving all the data used in scripts.
Results directory is for saving all the ouput results of scripts.
Sandbox directory is for experiment and testing codes. 
I put sandbox directoies into gitignore since nothing important in these directories.


**********************************************************************

======================================================================
Looking for the weekly directories...

Found 3 weekly directories: week1, week2, week3

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: writeup, results, data, code

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
week3 content
code:
1. apply1.R
Demonstrates the use of the apply function on a matrix. It calculates the mean and variance for each row, and the mean for each column of a randomly generated 10x10 matrix.

2. apply2.R
Showcases the use of a custom function with the apply function. It applies a conditional operation to each row of a matrix, multiplying elements by 100 if their sum is positive.

3. basic_io.R
Introduces basic input/output operations in R. It includes reading a CSV file, writing and appending data to a file, and handling headers and row names.

4. boilerplate.R
A template script for creating and testing a simple function. It demonstrates basic function definition, argument handling, and output in R.

5. break.R
A simple demonstration of using a break statement in a loop. The script uses a while loop and exits it when i equals 10.

6. browse.R
Implements a function simulating exponential growth and demonstrates debugging with the browser() function. 

7. control_flow.R
An instructional script covering basic control flow structures, including if/else statements and for loops, with practical examples.

8. DataWrang.R
Focuses on loading and initial processing of the Pound Hill dataset, including data conversion and basic transformations.

9. DataWrangTidy.R
Demonstrates data wrangling using tidyverse. It transposes a dataset, replaces missing values, and reshapes it from wide to long format.

10. Florida.R
Performs statistical analysis on temperature data, including a permutation test to assess the significance of an observed correlation coefficient.

11. Girko.R
Centers on mathematical operations involving eigenvalues and ellipses, including a custom function for building ellipses.

12. GPDD_Data.R
Visualizes geographic data by superimposing data points on a world map. And discuissed about the biases that might occured in analysis based on the given data.

13. MyBars.R
Uses ggplot2 to create visualizations with lineranges, demonstrating complex plotting techniques.

14. next.R
A script demonstrating the use of the next statement in loops. It skip iterations when the number is even. Therefore, it can only prints odd numbers.

15. plotLin.R
Demonstrates linear regression analysis and data visualization.

16. PP_Dists.R
Focuses on analyzing a predator-prey dataset, including transforming data into logarithmic form and calculating statistical summaries by feeding type.

17. PP_Regress.R
Performs grouped linear regression analysis on predator-prey data, summarizing key regression statistics like slope, intercept, and R-squared.

18. preallocate.R
Illustrates the importance of preallocating memory in loops by comparing execution times of functions with and without preallocation.

19. R_conditionals.R
Showcases the use of conditional statements in R through functions that perform checks like evenness, power of 2, and primality.

20. Ricker.R
Simulates the Ricker model for population dynamics.

21. sample.R
Includes functions for sampling from a population and calculating means, emphasizing the impact of memory preallocation in loops.

22. SQLinR.R
Demonstrates the integration of SQL database operations within R.

23. TreeHeight.R
Calculates tree heights using trigonometry based on distance and angle measurements. Reads tree data from a CSV file and applies a mathematical formula for height calculation.

24. TreeHeight_edit.R
This funtion is the modified TreeHeight.R, whcih is the script for Tree heights practals. Names it TreeHeight_edit.R to distinguish it from TreeHeight.R.

25. try.R
Showcases error handling and conditional execution in R using a custom sampling function, demonstrating the use of try for managing errors in loops.

26. Vectorize1.R
Illustrates the efficiency difference between loop-based and vectorized operations in R.

27. Vectorize2.R
Implements a stochastic version of the Ricker model using both loop-based and vectorized approaches.

data:
1. EcolArchives-E089-51-D1.csv
represents the traits of birds of diffrent species.
2. GPDDFiltered.RData
Map data from Global Population Dynamics Database
3. KeyWestAnnualMeanTemperature.RData
Data of annual mean temperature from Key West in Florida, USA for the 20th century.
4. PoundHillData.csv
Field data for wrangling.
5. PoundHillMetaData.csv
The metadata of PoundHillData.csv.
6. Results.txt
A set of data used in MyBars.R for producing plots.
7. trees.csv
Data of trees including the species, distance, angle degree and tree heights. 

results:
All the output results should be put in this directory.

writeup:
Get the results first, and then run Florida.tex. Since this file needs the output figures.I put Florida.tex in a seperate directory which is called writeup. The pdf outputs are also in writeup directory.
**********************************************************************

Results directory is empty - good! 

Found 28 code files: PP_Dists.R, TreeHeight_edit.R, Vectorize2.R, break.R, sample.R, Vectorize1.R, PP_Regress.R, R_conditionals.R, apply1.R, basic_io.R, GPDD_Data.R, SQLinR.R, Girko.R, Florida.R, DataWrangTidy.R, boilerplate.R, apply2.R, DataWrang.R, try.R, control_flow.R, Ricker.R, MyBars.R, TreeHeight.R, plotLin.R, Florida.tex, next.R, browse.R, preallocate.R

======================================================================
Testing script/code files...

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
#load necessary libraries
library(ggplot2)
library(dplyr)

#read the predator-prey dataset
data <- read.csv(paste0("../data/EcolArchives-E089-51-D1.csv"))

#convert masses and size ratios to logarithms
data$log_predator_mass <- log(data$Predator.mass)
data$log_prey_mass <- log(data$Prey.mass)
data$log_size_ratio <- log(data$Prey.mass / data$Predator.mass)

#calculate mean and median values by feeding type
summary_stats <- data %>%
  group_by(Type.of.feeding.interaction) %>%
  summarize(
    Mean_log_predator_mass = mean(log_predator_mass),
    Median_log_predator_mass = median(log_predator_mass),
    Mean_log_prey_mass = mean(log_prey_mass),
    Median_log_prey_mass = median(log_prey_mass),
    Mean_log_size_ratio = mean(log_size_ratio),
    Median_log_size_ratio = median(log_size_ratio)
  )

#save statistics to a CSV file
write.csv(summary_stats, file = paste0("../results/PP_Results.csv"), row.names = FALSE)

#create subplots for predator mass, prey mass, and size ratio by feeding type
pdf("../results/Pred_Subplots.pdf")
par(mfrow = c(2, 2))

for (feed_type in unique(data$Type.of.feeding.interaction)) {
  subset_data <- subset(data, Type.of.feeding.interaction == feed_type)
  plot(density(subset_data$log_predator_mass), main = paste("Predator Mass -", feed_type), xlab = "Log Predator Mass")
}
dev.off()

pdf("../results/Prey_Subplots.pdf")
par(mfrow = c(2, 2))
for (feed_type in unique(data$Type.of.feeding.interaction)) {
  subset_data <- subset(data, Type.of.feeding.interaction == feed_type)
  plot(density(subset_data$log_prey_mass), main = paste("Prey Mass -", feed_type), xlab = "Log Prey Mass")
}
dev.off()

pdf("../results/SizeRatio_Subplots.pdf")
par(mfrow = c(2, 2))
for (feed_type in unique(data$Type.of.feeding.interaction)) {
  subset_data <- subset(data, Type.of.feeding.interaction == feed_type)
  plot(density(subset_data$log_size_ratio), main = paste("Size Ratio -", feed_type), xlab = "Log Size Ratio")
}
dev.off()


#another way to do it
ggplot(data, aes(x = log_predator_mass)) +
  geom_density() +
  facet_wrap(~ Type.of.feeding.interaction) +
  labs(title = "Predator mass")
#ggsave("../results/Pred_Subplots_dw.pdf", device = "pdf")
**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called ‘ggplot2’
Execution halted

======================================================================
Inspecting script file TreeHeight_edit.R...

File contents are:

**********************************************************************
# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

TreeData <- read.csv("../data/trees.csv")
head(TreeData)
TreeLength <- length(TreeData$Distance.m)
TreeData$Distance.m[2]

TreeHeight <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    print(paste("Tree height is:", height))
  
    return (height)
}

#Load required libraries
library(dplyr)
#Load the data
data <- read.csv("../data/trees.csv")
#Calculate tree heights
data <- data %>%
  mutate(Tree.Height.m = TreeHeight(Angle.degrees, Distance.m))
#Save the results
write.csv(data, file = "../results/TreeHts.csv", row.names = FALSE)


**********************************************************************

Testing TreeHeight_edit.R...

Output (only first 500 characters): 


**********************************************************************
             Species Distance.m Angle.degrees
1    Populus tremula   31.66583      41.28264
2      Quercus robur   45.98499      44.53592
3      Ginkgo biloba   31.24177      25.14626
4 Fraxinus excelsior   34.61667      23.33613
5     Betula pendula   45.46617      38.34913
6     Betula pendula   48.79550      33.59231
[1] 45.98499

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(dplyr) : there is no package called ‘dplyr’
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list = ls())

stochrick <- function(p0 = runif(1000, 0.5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{

  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix

  N[1, ] <- p0

  for (pop in 1:length(p0)) { #loop through the populations

    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)

}
system.time(stochrick())

# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 

# print("Vectorized Stochastic Ricker takes:")
# print(system.time(res2<-stochrickvect()))

rm(list = ls())

stochrickvect <- function(p0 = runif(1000, 0.5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{

  N <- matrix(NA, numyears, length(p0))#initialize empty matrix

  N[1, ] <- p0
#generate random fluctuations for all years at once
  fluctuations <- matrix(rnorm(numyears * length(p0), mean = 0, sd = sigma), nrow = numyears)
    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr, ] <- N[yr-1, ] * exp(r * (1 - N[yr - 1, ] / K) + fluctuations[yr, ]) 
      #add one fluctuation from normal distribution
    
     }
  
 return(N)

}

print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))

**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
   user  system elapsed 
  0.127   0.012   0.139 
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.008   0.000   0.008 

**********************************************************************

Code ran without errors

Time consumed = 0.27005s

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************
i <- 0 #Initialize i
    while (i < Inf) {
        if (i == 10) {
            break 
        } else { # Break out of the while loop!  
            cat("i equals " , i , " \n")
            i <- i + 1 # Update i
    }
}
**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.09564s

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}

## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}

## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}

set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)

n <- 100 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment

print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))

print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))

print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))

print("Using the vectorized sapply function (on a list) took:" )
print(system.time(sapply_sample(popn, n, num)))

print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))
**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops without preallocation on a vector took:"
   user  system elapsed 
  0.172   0.019   0.192 
[1] "Using loops with preallocation on a vector took:"
   user  system elapsed 
  0.125   0.001   0.124 
[1] "Using loops with preallocation on a list took:"
   user  system elapsed 
  0.116   0.000   0.116 
[1] "Using the vectorized sapply function (on a list) took:"
   user  system elapsed 
  0.115   0.000   0.115 
[1] "Using the vectorized lapply function (on a list) took:"
   user  syst
**********************************************************************

Code ran without errors

Time consumed = 0.84133s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M) {
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]) {
    for (j in 1:Dimensions[2]) {
      Tot <- Tot + M[i,j]
    }
  }
  return (Tot)
}
 
print("Using loops, the time taken is:")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is:")
print(system.time(sum(M)))
**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.031   0.000   0.030 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.000   0.000   0.001 

**********************************************************************

Code ran without errors

Time consumed = 0.15338s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
#load necessary libraries
library(ggplot2)
library(dplyr)

#set the path to the dataset and read it
data <- read.csv("../data/EcolArchives-E089-51-D1.csv", header = TRUE, sep = ",", stringsAsFactors = TRUE)

regression_results <- data %>%
  group_by(Type.of.feeding.interaction, Predator.lifestage) %>%
  do(model = lm(Prey.mass ~ Predator.mass, data = .)) %>%
  summarize(
    slope = coef(model)[[2]],
    intercept = coef(model)[[1]],
    R = summary(model)$r.squared,
    F_statistic = summary(model)$fstatistic[1],
    p_value = summary(model)$fstatistic[2]
  )

write.csv(regression_results, "../results/PP_Regress_Results.csv", row.names = FALSE)

 #save plot as a PDF in the Results directory
ggplot(data, aes(x = log(Predator.mass), y = log(Prey.mass), color = Predator.lifestage)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(.~Type.of.feeding.interaction) +
  labs(title = "Linear Regression on Predator-Prey Interactions") +
  theme_minimal()
ggsave("../results/PP_Regress_plot.pdf", device = "pdf")
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called ‘ggplot2’
Execution halted

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************
# Checks if an integer is even
is.even <- function(n = 2) {
  if (n %% 2 == 0) {
    return(paste(n,'is even!'))
  } else {
  return(paste(n,'is odd!'))
  }
}

is.even(6)

# Checks if a number is a power of 2
is.power2 <- function(n = 2) {
  if (log2(n) %% 1==0) {
    return(paste(n, 'is a power of 2!'))
  } else {
  return(paste(n,'is not a power of 2!'))
    }
}

is.power2(4)

# Checks if a number is prime
is.prime <- function(n) {
  if (n==0) {
    return(paste(n,'is a zero!'))
  } else if (n==1) {
    return(paste(n,'is just a unit!'))
  }
    
  ints <- 2:(n-1)
  
  if (all(n%%ints!=0)) {
    return(paste(n,'is a prime!'))
  } else {
  return(paste(n,'is a composite!'))
    }
}

is.prime(3)
**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is even!"
[1] "4 is a power of 2!"
[1] "3 is a prime!"

**********************************************************************

Code ran without errors

Time consumed = 0.08349s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
M <- matrix(rnorm(100), 10, 10)
RowMeans <- apply(M, 1, mean)
print(RowMeans)

ColMeans <- apply(M, 2, mean)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)
**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1]  0.03976439 -0.52757981 -0.48965231 -0.12877885 -0.69601691  0.41615967
 [7]  0.14310550 -0.24969138  0.11482369 -0.11488767
 [1] 1.2351906 0.5603924 0.2974335 1.2102605 0.3965285 1.3931381 0.3098520
 [8] 0.8299438 1.1574612 0.7691612
 [1] -0.22362140 -0.06735011 -0.08025205  0.33551070 -0.46580854 -0.14268508
 [7]  0.02998943  0.14873622 -0.44794940 -0.57932345

**********************************************************************

Code ran without errors

Time consumed = 0.08176s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names=FALSE) # ignore column names

**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Warning message:
In write.table(MyData[1, ], file = "../results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
#Load necessary libraries
library(maps)

# Load GPDD data
load("../data/GPDDFiltered.RData")

#Create a world map
map("world")

#Superimpose locations from GPDD dataframe
points(gpdd$long, gpdd$lat, col = "red", pch = 1)

#Potential biases in the GPDD dataset
#As observed in the map, biases may include:
#1. Spatial bias: Most of data might from the areas with higher research efforts and more advanced techniques. leading to an uneven geographical representation.
#2. bias caused by location limitation: data collection might be easier in easily accessible areas. The data might be less in regions hard to access.
#3. Bias towards certain species: Some species might be more heavily studied and easy to collect the data.



**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(maps) : there is no package called ‘maps’
Execution halted

======================================================================
Inspecting script file SQLinR.R...

File contents are:

**********************************************************************
#install the sqlite package
install.packages('sqldf')

# To load the packages
library(sqldf)

# The command below opens a connection to the database.
#If the database does not yet exist, one is created in the working directory of R.
db <- dbConnect(SQLite(), dbname='Test.sqlite')

# Now let's enter some data to the table
# Using the db connection to our database, the data are entered using SQL queries
# The next command just create the table
dbSendQuery(conn = db,
            "CREATE TABLE Consumer
       (OriginalID TEXT,
        ConKingdom TEXT,
        ConPhylum TEXT,
        ConSpecies TEXT)")

# Once the table is created, we can enter the data.
#INSERT specifies where the data is entered (here the School table).
#VALUES contains the data

 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (1, 'Animalia', 'Arthropoda', 'Chaoborus trivittatus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (2, 'Animalia', 'Arthropoda', 'Chaoborus americanus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (3, 'Animalia', 'Chordata', 'Stizostedion vitreum')")


# Once we have our table, we can query the results using:

dbGetQuery(db, "SELECT * FROM Consumer")
dbGetQuery(db, "SELECT * FROM Consumer WHERE ConPhylum='Chordata'")


# Tables can be also imported from csv files.
# As example, let's use the Biotraits dataset.
# The easiest way is to read the csv files into R as data frames.
# Then the data frames are imported into the database.

Resource <- read.csv("../Data/Resource.csv")  # Read csv files into R

# Import data frames into database
 dbWriteTable(conn = db, name = "Resource", value = Resource, row.names = FALSE)

# Check that the data have been correctly imported into the School table.
 dbListTables(db)                 # The tables in the database
 dbListFields(db,"Resource")       # The columns in a table
 dbReadTable(db, "Resource")    # The data in a table

# Before leaving RSQLite, there is a bit of tidying-up to do.
# The connection to the database is closed, and as precaution
# the three data frames are removed from R’s environment.
 dbDisconnect(db)            # Close connection
 rm(list = c("Resource"))   # Remove data frames



**********************************************************************

Testing SQLinR.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
Warning in install.packages("sqldf") :
  'lib = "/usr/local/lib/R/site-library"' is not writable
Error in install.packages("sqldf") : unable to install packages
Execution halted

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
p
pdf("../results/Girko.pdf")
print(p)
dev.off()
**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(eigDF, aes(x = Real, y = Imaginary)) : 
  could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file Florida.R...

File contents are:

**********************************************************************
rm(list=ls())

load("../data/KeyWestAnnualMeanTemperature.RData")
ls()
class(ats)
head(ats)
plot(ats)

#calculate the observed correlation coefficient
observed_cor <- cor(ats$Year, ats$Temp)
#set the number of permutations
n_permutations <- 10000
#initialize a vector to store random correlation coefficients
rand_cor <- numeric(n_permutations)

#perform the permutation test
for (i in 1:n_permutations) {
  #shuffle the temperature data
  shuffled_temp <- sample(ats$Temp)
  
  #calculate the correlation coefficient for the shuffled data
  rand_cor[i] <- cor(ats$Year, shuffled_temp)
}

library(ggplot2)

#create a density plot of random correlation coefficients
ggplot(data.frame(rand_cor = rand_cor), aes(x = rand_cor)) +
  geom_density(fill = "skyblue", color = "black") +
  labs(title = "Density Plot of Random Correlation Coefficients",
       x = "Correlation Coefficients",
       y = "Density")+
  geom_vline(xintercept = observed_cor, linetype = "dashed", color = "red", size = 1)
ggsave("../results/Florida_plot.pdf", device = "pdf")

observed_cor
#caculate the p-value
p_value <- sum(rand_cor >= observed_cor) / n_permutations

p_value


**********************************************************************

Testing Florida.R...

Output (only first 500 characters): 


**********************************************************************
[1] "ats"
[1] "data.frame"
  Year     Temp
1 1901 23.75000
2 1902 24.66667
3 1903 24.71667
4 1904 24.51667
5 1905 24.88333
6 1906 24.63333

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(ggplot2) : there is no package called ‘ggplot2’
Execution halted

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
#load the library
library(tidyverse)

#read the dataset
MyData <- read.csv("../data/PoundHillData.csv", header = FALSE)
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

#transpose the dataset
MyData <- as.data.frame(t(MyData))
MyData[MyData == ""] <- 0

#convert from wide to long format
TempData <- MyData[-1,] #remove the first row
colnames(TempData) <- MyData[1,] #set column names from the original data

MyWrangledData <- TempData%>%
  gather(key = "Species", value = "Count", -Cultivation, -Block, -Plot, -Quadrat) %>%
  mutate(
    Cultivation = as.factor(Cultivation),
    Block = as.factor(Block),
    Plot = as.factor(Plot),
    Quadrat = as.factor(Quadrat),
    Count = as.integer(Count)
  )


str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)
**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in library(tidyverse) : there is no package called ‘tidyverse’
Execution halted

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# A boilerplate R script

MyFunction <- function(Arg1, Arg2) {
  
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
    
  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test

pesudo repelication 
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error: unexpected symbol in "pesudo repelication"
Execution halted

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
someOperation <- function(v) {
    if (sum(v) > 0) {
        reutrn (v * 100)
    } else {
        reutrn(v)
    }
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, someOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in reutrn(v * 100) : could not find function "reutrn"
Calls: print -> apply -> FUN
Execution halted

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: reshape2
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called ‘reshape2’
Error in melt(TempData, id = c("Cultivation", "Block", "Plot", "Quadrat"),  : 
  could not find function "melt"
Execution halted

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************
doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
        } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }

set.seed(1345) # again, to get the same result for illustration

popn <- rnorm(50)

hist(popn)


result <- lapply(1:15, function(i) try(doit(popn), FALSE))
**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: -0.11620822588674"
[1] "Mean of this sample was: -0.0468516755995931"
[1] "Mean of this sample was: -0.0890228211466614"
[1] "Mean of this sample was: -0.124229742255296"
[1] "Mean of this sample was: 0.0314144452816157"
[1] "Mean of this sample was: -0.233476945796405"
[1] "Mean of this sample was: -0.196681538928001"
[1] "Mean of this sample was: 0.0146969612111605"
[1] "Mean of this sample was: -0.234913159471725"
[1] "Mean of this sample was: -0.0497464588165691"
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
#if statements
a <- TRUE
if (a == TRUE) {
    print ("a is TRUE")
} else {
    print ("a is FALSE")
}

z <- runif(1) ## Generate a uniformly distributed random number
if (z <= 0.5) {
    print ("Less than a half")
    }

#for loops
for (i in 1:10) {
    j <- i * i
    print(paste(i, " squared is", j ))
}

for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')) {
      print(paste('The species is', species))
}

v1 <- c("a","bc","def")
for (i in v1) {
    print(i)
}

#while loops
i <- 0
while (i < 10) {
    i <- i+1
    print(i^2)
}

**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.10681s

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************

**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.09730s

======================================================================
Inspecting script file MyBars.R...

File contents are:

**********************************************************************
a <- read.table("../data/Results.txt", header = TRUE)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 
p

pdf("../results/MyBars.pdf")
print(p)
dev.off()
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(a) : could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

TreeData <- read.csv("../data/trees.csv")
head(TreeData)
TreeLength <- length(TreeData$Distance.m)
TreeData$Distance.m[2]

TreeHeight <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    print(paste("Tree height is:", height))
  
    return (height)
}

TreeHeight(37, 40)

**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************
             Species Distance.m Angle.degrees
1    Populus tremula   31.66583      41.28264
2      Quercus robur   45.98499      44.53592
3      Ginkgo biloba   31.24177      25.14626
4 Fraxinus excelsior   34.61667      23.33613
5     Betula pendula   45.46617      38.34913
6     Betula pendula   48.79550      33.59231
[1] 45.98499
[1] "Tree height is: 30.1421620041118"
[1] 30.14216

**********************************************************************

Code ran without errors

Time consumed = 0.09439s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")

p

pdf("../results/MyLinReg.pdf")
print(p)
dev.off()
**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in ggplot(my_data, aes(x = x, y = y, colour = abs(my_lm$residual))) : 
  could not find function "ggplot"
Execution halted

======================================================================
Inspecting script file Florida.tex...

File contents are:

**********************************************************************
\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\usepackage{titling}

\setlength{\droptitle}{-14em}
\title{Is Florida getting warmer?}
\author{Zhongbin Hu}
\date{21/10/2023}

\begin{document}

  \maketitle

  \section{Results}
  \begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{../results/Florida_plot.pdf}
    \caption{Distribution of Permutation Correlation Coefficients with Observed Coefficient}
    \label{Florida}
  \end{figure}

The figure above includes the permuted corrlation coefficients and observed coefficient(red line).The observed correlation coefficient between years and temperature in the original dataset was calculated to be around 0.5331784. 
After 10,000 permutations and caculation, it was found that all of 10,000 permuted correlation coefficients were smaller or equal than the observed one. The approximate p-value is 0 after caculation.

\section{Interpretation}
From the figure the permuted correlation coefficients is nearly normaly distributed, and the observed coefficient is larger than all the permuted coefficient. This means the observed coefficient hardly occured by random chance.
In addition, the approximate samll p-value obtained from the permutation test suggests that the correlation between years and temperature is statistically significant.
Since the observed coefficient is larger than 0, there is a positive correlation between the year and temperature.
Therefore, the data supports the hypothesis that there is a significant correlation between the year and temperature Florida during the 20th century and Florida is becoming warmer.


\end{document}

**********************************************************************

Testing Florida.tex...

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************
for (i in 1:10) {
  if ((i %% 2) == 0) # check if the number is odd
    next # pass to next iteration of loop 
  print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.11273s

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.13741s

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
NoPreallocFun <- function(x) {
    a <- vector() # empty vector
    for (i in 1:x) {
        a <- c(a, i) # concatenate
    }
}

print(system.time(NoPreallocFun(1000)))

PreallocFun <- function(x) {
    a <- rep(NA, x) # pre-allocated vector
    for (i in 1:x) {
        a[i] <- i # assign
    }
}

print(system.time(PreallocFun(1000)))
**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
   user  system elapsed 
  0.004   0.007   0.011 
   user  system elapsed 
  0.001   0.000   0.002 

**********************************************************************

Code ran without errors

Time consumed = 0.14258s

======================================================================
======================================================================
Finished running scripts

Ran into 15 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!